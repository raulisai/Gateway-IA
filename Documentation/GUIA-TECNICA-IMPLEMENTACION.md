---
title: Gu√≠a T√©cnica de Implementaci√≥n
type: documentacion_tecnica
created: '2026-01-11'
tags:
  - documentacion
  - tecnica
  - guia
  - prompts
---
# üìò LLM Gateway - Gu√≠a T√©cnica de Implementaci√≥n

> **Documento estilo Prompt**: Consideraciones t√©cnicas, decisiones de dise√±o y mejores pr√°cticas para implementar cada componente del sistema

---

## üéØ Prop√≥sito del Documento

Esta gu√≠a proporciona el "qu√©" y el "c√≥mo" conceptual para implementar el LLM Gateway, sin incluir c√≥digo espec√≠fico. Est√° dise√±ada como un conjunto de prompts t√©cnicos que describen las consideraciones clave para cada componente.

---

## üèóÔ∏è PARTE 1: ARQUITECTURA GENERAL

### 1.1 Decisiones de Dise√±o del Sistema

#### Arquitectura de Microservicios con Docker Compose

**¬øQu√© se necesita considerar?**
- El sistema se divide en 3 contenedores independientes: frontend, backend, updater
- Cada contenedor tiene su propio Dockerfile con dependencias espec√≠ficas
- Los contenedores se comunican a trav√©s de una red bridge de Docker
- El volumen compartido `./data` permite persistencia de SQLite y models.json
- Los puertos 3000 (frontend) y 8000 (backend) se exponen al host

**¬øPor qu√© esta arquitectura?**
- **Separaci√≥n de responsabilidades**: Cada servicio tiene un prop√≥sito √∫nico
- **Escalabilidad independiente**: Se pueden escalar servicios por separado
- **Desarrollo paralelo**: Frontend y backend se desarrollan independientemente
- **Facilidad de deployment**: Docker Compose simplifica el despliegue

**Consideraciones importantes:**
- El updater debe ser un servicio "fire-and-forget" que no bloquea el backend
- La red bridge debe permitir comunicaci√≥n entre backend y frontend por nombre de servicio
- Los vol√∫menes deben tener permisos correctos para lectura/escritura
- Las variables de entorno sensibles deben manejarse con archivos .env

---

### 1.2 Flujo de Datos Principal

#### Pipeline de Procesamiento de Requests

**Flujo completo que debe implementarse:**

```
Request ‚Üí Authentication ‚Üí Cache Check ‚Üí [Cache Hit] ‚Üí Return Cached
                                      ‚Üì [Cache Miss]
                              Classification ‚Üí Routing ‚Üí Provider Call ‚Üí Response
                                                                          ‚Üì
                                                                  Cache + Log ‚Üí Return
```

**Consideraciones para cada etapa:**

1. **Authentication**
   - Validar que el gateway key exista y est√© activo
   - Verificar que no haya expirado
   - Cargar datos del usuario para tracking
   - Rechazar requests inv√°lidos inmediatamente (fail-fast)

2. **Cache Check**
   - Generar hash √∫nico del request (messages + par√°metros relevantes)
   - Buscar en cache en memoria (debe ser O(1))
   - Verificar que TTL no haya expirado
   - Si hay hit, registrar m√©trica pero NO loguear como request completo

3. **Classification**
   - Contar tokens del prompt usando tiktoken
   - Analizar caracter√≠sticas: longitud, complejidad l√©xica, dominio
   - Asignar nivel: simple (<500 tokens), moderate (500-2000), complex (2000-8000), expert (>8000)
   - La clasificaci√≥n debe ser r√°pida (<50ms)

4. **Routing**
   - Filtrar modelos disponibles por: context window, health status, rate limits
   - Calcular score para cada modelo: `score = (quality_weight/cost) + speed_bonus`
   - Seleccionar modelo con mayor score
   - Tener estrategia de fallback si modelo primario falla

5. **Provider Call**
   - Desencriptar API key del usuario para el provider seleccionado
   - Construir request en formato espec√≠fico del provider
   - Hacer llamada HTTP con timeout (30s default)
   - Manejar retry con exponential backoff: 1s, 2s, 4s, 8s
   - Normalizar respuesta a formato est√°ndar

6. **Cache + Log**
   - Guardar respuesta en cache con TTL de 1 hora
   - Insertar registro en DB: tokens, costo, latencia, modelo usado
   - Actualizar m√©tricas agregadas en memoria
   - No bloquear la respuesta al usuario

---

## üîí PARTE 2: SEGURIDAD Y AUTENTICACI√ìN

### 2.1 Sistema de Encriptaci√≥n de API Keys

#### ¬øQu√© se debe implementar?

**Problema a resolver:**
Los usuarios proporcionan API keys de terceros (OpenAI, Anthropic) que deben almacenarse de forma segura en la base de datos. Si alguien obtiene acceso a la DB, no debe poder leer las keys en texto plano.

**Soluci√≥n: Encriptaci√≥n sim√©trica con Fernet**

**Componentes necesarios:**

1. **Master Password**
   - Variable de entorno `MASTER_ENCRYPTION_KEY` (m√≠nimo 32 caracteres)
   - NO debe estar en c√≥digo ni en Git
   - Debe ser √∫nica por instalaci√≥n
   - Si se pierde, las keys encriptadas son irrecuperables

2. **Derivaci√≥n de Key**
   - Usar PBKDF2 para derivar key criptogr√°fica desde master password
   - Agregar salt √∫nico por instalaci√≥n (almacenado en DB o config)
   - Iteraciones: 100,000+ para resistencia a brute force

3. **Proceso de Encriptaci√≥n**
   ```
   API Key (plaintext) ‚Üí Fernet.encrypt() ‚Üí Encrypted Key (bytes) ‚Üí Base64 ‚Üí Store in DB
   ```

4. **Proceso de Desencriptaci√≥n**
   ```
   DB ‚Üí Base64 ‚Üí Encrypted Key (bytes) ‚Üí Fernet.decrypt() ‚Üí API Key (plaintext) ‚Üí Use
   ```

**Consideraciones cr√≠ticas:**
- La desencriptaci√≥n solo debe ocurrir en memoria, justo antes de usar la key
- NUNCA loguear o retornar keys desencriptadas en responses
- Implementar rate limiting en endpoints que usan keys para prevenir abuse
- Considerar key rotation: permitir re-encriptar con nueva master key

---

### 2.2 Autenticaci√≥n JWT

#### ¬øC√≥mo debe funcionar?

**Sistema de tokens para autenticar usuarios del dashboard**

**Componentes:**

1. **Registro (Signup)**
   - Recibir email + password
   - Validar formato de email (regex)
   - Validar fortaleza de password (min 8 chars, may√∫scula, n√∫mero)
   - Hash password con bcrypt (cost factor 12)
   - Crear usuario en DB
   - Auto-generar primer gateway key para el usuario
   - Retornar JWT token

2. **Login**
   - Recibir email + password
   - Buscar usuario por email
   - Comparar password con bcrypt.verify()
   - Si v√°lido, generar JWT token
   - Token contiene: user_id, email, exp (24h), iat

3. **JWT Token Structure**
   ```json
   {
     "user_id": "uuid",
     "email": "user@example.com",
     "iat": 1234567890,
     "exp": 1234654290
   }
   ```

4. **Validaci√≥n de Token**
   - Middleware intercepta requests con header `Authorization: Bearer <token>`
   - Verificar firma del token con SECRET_KEY
   - Verificar que no haya expirado
   - Extraer user_id y adjuntar al request para uso posterior
   - Rechazar con 401 si inv√°lido o expirado

**Consideraciones:**
- SECRET_KEY debe ser fuerte (32+ caracteres aleatorios)
- Implementar refresh tokens si se requiere sesi√≥n persistente
- Considerar invalidaci√≥n de tokens (logout) con blacklist en Redis/cache
- NO almacenar informaci√≥n sensible en el token (es decodificable)

---

## üß† PARTE 3: L√ìGICA DE NEGOCIO CORE

### 3.1 Request Classifier

#### ¬øC√≥mo clasificar requests autom√°ticamente?

**Objetivo:** Analizar el request del usuario y determinar qu√© tan "complejo" es para elegir el modelo apropiado.

**Factores a considerar:**

1. **Token Count (peso: 60%)**
   - Usar tiktoken para contar tokens del prompt
   - Rangos sugeridos:
     - Simple: 0-500 tokens
     - Moderate: 501-2000 tokens  
     - Complex: 2001-8000 tokens
     - Expert: 8000+ tokens

2. **Complejidad L√©xica (peso: 20%)**
   - Presencia de t√©rminos t√©cnicos (c√≥digo, math, ciencia)
   - Longitud promedio de palabras
   - Uso de jerga especializada
   - Detecci√≥n de c√≥digo (markdown, snippets)

3. **Tipo de Tarea (peso: 20%)**
   - QA simple: "¬øCu√°l es la capital de Francia?"
   - An√°lisis: "Compara estos dos documentos"
   - Generaci√≥n creativa: "Escribe un cuento"
   - Razonamiento complejo: "Resuelve este problema matem√°tico"
   - Coding: "Implementa esta funci√≥n"

**Implementaci√≥n sugerida:**

```
def classify_request(messages, parameters):
    1. Contar tokens totales
    2. Extraer features del texto (keywords, c√≥digo, preguntas)
    3. Calcular score ponderado
    4. Mapear score a nivel de complejidad
    5. Retornar: {
         "complexity": "moderate",
         "estimated_tokens": 1500,
         "features": ["code", "analysis"]
       }
```

**Consideraciones:**
- Debe ser r√°pido (<50ms) para no agregar latencia
- Puede empezar simple (solo token count) y evolucionar
- En futuro, usar modelo ML ligero para clasificaci√≥n m√°s precisa
- Cachear clasificaciones de prompts similares

---

### 3.2 Routing Engine

#### ¬øC√≥mo seleccionar el mejor modelo?

**Problema:** Dados m√∫ltiples modelos disponibles, elegir el √≥ptimo bas√°ndose en complejidad, costo, velocidad y disponibilidad.

**Pipeline de decisi√≥n:**

1. **Cargar Modelos Disponibles**
   - Leer models.json del registry
   - Filtrar solo modelos para los cuales el usuario tiene API keys configuradas

2. **Filtrado por Requisitos**
   
   **Filtro 1: Context Window**
   - Calcular tokens necesarios: prompt + completion esperada + buffer (20%)
   - Eliminar modelos con context window insuficiente
   
   **Filtro 2: Provider Health**
   - Verificar si provider tuvo errores recientes (√∫ltimos 5 min)
   - Eliminar providers con tasa de error >50%
   
   **Filtro 3: Rate Limits**
   - Verificar requests por minuto del usuario con ese provider
   - Eliminar si se excedi√≥ l√≠mite

3. **Scoring de Modelos Restantes**

   **Formula sugerida:**
   ```
   score = (quality_multiplier / cost_per_1m_tokens) + speed_bonus
   
   donde:
   quality_multiplier = {
     simple: 1.0,
     moderate: 1.5,
     complex: 2.0,
     expert: 3.0
   }
   
   speed_bonus = {
     si latencia_promedio < 2s: +10
     si latencia_promedio < 5s: +5
     sino: 0
   }
   ```

4. **Selecci√≥n Final**
   - Ordenar modelos por score descendente
   - Retornar el top 1
   - Guardar top 3 como fallbacks en caso de falla

**Consideraciones:**
- El scoring debe reflejar las prioridades del negocio (costo vs calidad)
- Implementar estrategia de fallback autom√°tico: si modelo A falla, probar B
- Registrar m√©tricas de cu√°ntas veces se usa cada modelo
- Permitir override manual: usuario puede forzar un modelo espec√≠fico

---

### 3.3 Provider Manager

#### ¬øC√≥mo interactuar con m√∫ltiples APIs LLM?

**Desaf√≠o:** Cada proveedor (OpenAI, Anthropic, Google) tiene formato diferente de request/response.

**Patr√≥n de dise√±o: Adapter Pattern**

**Estructura necesaria:**

1. **BaseProvider (clase abstracta)**
   - M√©todos abstractos: `call()`, `validate_key()`, `format_request()`, `parse_response()`
   - M√©todos concretos: retry logic, error handling, timeout

2. **OpenAIProvider**
   - Endpoint: `https://api.openai.com/v1/chat/completions`
   - Headers: `Authorization: Bearer sk-...`
   - Body format: `{"model": "gpt-4", "messages": [...], "temperature": 0.7}`
   - Response format: `{choices: [{message: {content: "..."}}], usage: {...}}`

3. **AnthropicProvider**
   - Endpoint: `https://api.anthropic.com/v1/messages`
   - Headers: `x-api-key: sk-ant-...`, `anthropic-version: 2023-06-01`
   - Body format: `{"model": "claude-3", "messages": [...], "max_tokens": 1024}`
   - Response format: `{content: [{text: "..."}], usage: {...}}`

4. **GoogleProvider**
   - Endpoint: `https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent`
   - Headers: `x-goog-api-key: ...`
   - Body format: `{"contents": [{"parts": [{"text": "..."}]}]}`

**Proceso unificado:**

```
1. ProviderManager.call(provider_name, model, messages, params)
2. Seleccionar adapter correcto (OpenAI/Anthropic/Google)
3. Obtener y desencriptar API key del usuario
4. Formatear request al formato del provider
5. Hacer HTTP POST con timeout y retry
6. Parsear response al formato unificado
7. Retornar: {
     "content": "response text",
     "model": "gpt-4",
     "usage": {"prompt_tokens": 10, "completion_tokens": 50},
     "provider": "openai"
   }
```

**Manejo de errores:**

- **401 Unauthorized**: API key inv√°lida ‚Üí marcar key como inv√°lida en DB, notificar usuario
- **429 Rate Limit**: Demasiados requests ‚Üí esperar (retry-after header) o fallback a otro provider
- **500 Server Error**: Error temporal del provider ‚Üí retry con backoff exponencial
- **Timeout**: Sin respuesta en 30s ‚Üí cancelar y probar fallback

**Consideraciones:**
- Cada adapter debe normalizar errores a un formato com√∫n
- Implementar circuit breaker: si un provider falla 5 veces seguidas, no intentar por 5 minutos
- Loguear todas las llamadas para debugging
- Implementar streaming si el provider lo soporta (OpenAI, Anthropic)

---

## üíæ PARTE 4: PERSISTENCIA Y CACHE

### 4.1 Dise√±o de Base de Datos

#### Schema de SQLite

**Tablas principales:**

**1. users**
```sql
- id: UUID PRIMARY KEY
- email: VARCHAR UNIQUE NOT NULL
- password_hash: VARCHAR NOT NULL
- created_at: TIMESTAMP DEFAULT CURRENT_TIMESTAMP
- plan: VARCHAR DEFAULT 'free' (free/pro/enterprise)
- is_active: BOOLEAN DEFAULT true
```

**2. gateway_keys**
```sql
- id: UUID PRIMARY KEY
- user_id: UUID FOREIGN KEY ‚Üí users.id
- key_hash: VARCHAR NOT NULL (hash del key, no plaintext)
- prefix: VARCHAR (ej: "gw_abc123", primeros 10 chars)
- name: VARCHAR (nombre descriptivo dado por usuario)
- created_at: TIMESTAMP
- last_used_at: TIMESTAMP
- is_active: BOOLEAN DEFAULT true
- rate_limit: INTEGER DEFAULT 100 (requests por minuto)
```

**3. provider_keys**
```sql
- id: UUID PRIMARY KEY
- user_id: UUID FOREIGN KEY ‚Üí users.id
- provider: VARCHAR (openai/anthropic/google)
- encrypted_key: TEXT NOT NULL
- last_verified_at: TIMESTAMP (√∫ltima vez que se verific√≥ que funciona)
- is_active: BOOLEAN DEFAULT true
- created_at: TIMESTAMP
```

**4. request_logs**
```sql
- id: UUID PRIMARY KEY
- user_id: UUID FOREIGN KEY ‚Üí users.id
- gateway_key_id: UUID FOREIGN KEY ‚Üí gateway_keys.id
- endpoint: VARCHAR (/v1/chat/completions)
- complexity: VARCHAR (simple/moderate/complex/expert)
- provider: VARCHAR
- model: VARCHAR
- prompt_tokens: INTEGER
- completion_tokens: INTEGER
- total_tokens: INTEGER
- cost_usd: DECIMAL(10, 6)
- latency_ms: INTEGER
- cache_hit: BOOLEAN
- status_code: INTEGER
- error_message: TEXT (si hubo error)
- created_at: TIMESTAMP DEFAULT CURRENT_TIMESTAMP
```

**√çndices necesarios:**
```sql
CREATE INDEX idx_request_logs_user_created ON request_logs(user_id, created_at DESC);
CREATE INDEX idx_request_logs_model ON request_logs(model);
CREATE INDEX idx_gateway_keys_user ON gateway_keys(user_id);
CREATE INDEX idx_provider_keys_user_provider ON provider_keys(user_id, provider);
```

**Consideraciones:**
- Usar UUIDs para evitar enumeration attacks
- Implementar soft deletes (is_active flag) en lugar de DELETE
- Particionar request_logs por mes si crece mucho (>10M registros)
- Backup diario de gateway.db

---

### 4.2 Cache Manager

#### Sistema de cach√© LRU en memoria

**¬øPor qu√© cach√©?**
- Requests id√©nticos pueden reutilizar respuestas previas
- Ahorra dinero (no llamar a providers)
- Reduce latencia (cache hit es <10ms vs 2s de API call)

**Implementaci√≥n:**

1. **Cache Key Generation**
   ```
   cache_key = hash(
     messages (ordenados can√≥nicamente),
     model (si usuario especifica),
     temperature,
     max_tokens
   )
   ```
   - Usar SHA256 para generar hash determin√≠stico
   - Normalizar inputs para consistencia (ej: strip whitespace)

2. **Cache Structure**
   ```python
   cache = {
     "hash123": {
       "response": {...},
       "timestamp": 1234567890,
       "ttl": 3600,
       "hit_count": 5
     }
   }
   ```

3. **LRU Eviction**
   - Usar OrderedDict o librer√≠a cachetools
   - Tama√±o m√°ximo: 1000 entries
   - Cuando se llena, eliminar el menos recientemente usado
   - Mover entries al final cuando se acceden (marcar como "usado recientemente")

4. **TTL (Time To Live)**
   - Default: 1 hora
   - Verificar en cada lookup si ha expirado
   - Si expir√≥, eliminar y tratar como cache miss

**Proceso completo:**

```
1. Request llega
2. Generar cache_key
3. Buscar en cache
4. Si existe y TTL v√°lido:
   - Incrementar hit_count
   - Mover al final del LRU
   - Retornar respuesta inmediatamente
5. Si no existe (cache miss):
   - Procesar request normalmente
   - Al obtener respuesta, guardar en cache
   - Si cache lleno, evict LRU entry
```

**Consideraciones:**
- Cache debe ser thread-safe si backend usa workers concurrentes
- Implementar m√©tricas: cache hit rate = hits / (hits + misses)
- Permitir invalidar cache manualmente (clear all, clear by pattern)
- Cache no debe almacenar respuestas con errores
- Para producci√≥n, considerar Redis para cache distribuido

---

## üìä PARTE 5: ANALYTICS Y MONITORING

### 5.1 Sistema de Tracking de Costos

#### ¬øC√≥mo calcular costos preciso?

**Desaf√≠o:** Cada modelo tiene precio diferente para input tokens vs output tokens.

**Datos necesarios en models.json:**
```json
{
  "id": "gpt-4o",
  "pricing": {
    "prompt": 2.50,        // USD per 1M tokens
    "completion": 10.00    // USD per 1M tokens
  }
}
```

**F√≥rmula de c√°lculo:**
```
cost_usd = (
  (prompt_tokens / 1_000_000) * pricing.prompt +
  (completion_tokens / 1_000_000) * pricing.completion
)
```

**Proceso de logging:**

1. **Despu√©s de cada request exitoso:**
   ```python
   log_entry = {
     user_id: ...,
     model: "gpt-4o",
     prompt_tokens: 150,
     completion_tokens: 500,
     cost_usd: calculate_cost(model, tokens),
     latency_ms: 2340,
     cache_hit: false,
     timestamp: now()
   }
   db.request_logs.insert(log_entry)
   ```

2. **Actualizar agregados en memoria:**
   ```python
   user_metrics[user_id]["daily_cost"] += cost_usd
   user_metrics[user_id]["daily_requests"] += 1
   model_usage[model] += 1
   ```

3. **Persistir agregados peri√≥dicamente:**
   - Cada hora: guardar snapshot en DB
   - Permite queries r√°pidas sin recalcular todo

**Consideraciones:**
- Redondear costos a 6 decimales para precisi√≥n
- Verificar precios actualizados desde model registry
- Alertar usuario si supera presupuesto diario/mensual
- Exportar logs a CSV/JSON para facturaci√≥n

---

### 5.2 Analytics Endpoints

#### ¬øQu√© m√©tricas exponer en el dashboard?

**Endpoint 1: Overview (/api/analytics/overview)**

**Query de ejemplo:**
```sql
SELECT 
  COUNT(*) as total_requests,
  SUM(cost_usd) as total_cost,
  AVG(latency_ms) as avg_latency,
  SUM(CASE WHEN cache_hit THEN 1 ELSE 0 END) * 100.0 / COUNT(*) as cache_rate
FROM request_logs
WHERE user_id = ? AND created_at > NOW() - INTERVAL '24 hours'
```

**Response:**
```json
{
  "total_requests": 1523,
  "total_cost": 4.52,
  "avg_latency_ms": 2100,
  "cache_hit_rate": 23.5,
  "period": "24h"
}
```

**Endpoint 2: Cost Breakdown (/api/analytics/cost-breakdown?days=7)**

**Query de ejemplo:**
```sql
SELECT 
  DATE(created_at) as date,
  SUM(cost_usd) as cost,
  COUNT(*) as requests
FROM request_logs
WHERE user_id = ? AND created_at > NOW() - INTERVAL '7 days'
GROUP BY DATE(created_at)
ORDER BY date ASC
```

**Response:**
```json
{
  "data": [
    {"date": "2026-01-05", "cost": 0.85, "requests": 320},
    {"date": "2026-01-06", "cost": 1.20, "requests": 450},
    ...
  ]
}
```

**Endpoint 3: Model Distribution (/api/analytics/model-distribution)**

**Query de ejemplo:**
```sql
SELECT 
  model,
  COUNT(*) as count,
  SUM(cost_usd) as total_cost
FROM request_logs
WHERE user_id = ? AND created_at > NOW() - INTERVAL '30 days'
GROUP BY model
ORDER BY count DESC
```

**Response:**
```json
{
  "models": [
    {"model": "gpt-4o-mini", "requests": 850, "cost": 2.10, "percentage": 55.8},
    {"model": "claude-3-haiku", "requests": 430, "cost": 0.80, "percentage": 28.2},
    {"model": "gpt-4o", "requests": 243, "cost": 6.50, "percentage": 15.9}
  ]
}
```

**Consideraciones:**
- Implementar paginaci√≥n para grandes datasets
- Cachear resultados de analytics por 1 minuto
- Permitir filtros: por modelo, por rango de fechas, por complejidad
- Optimizar queries con √≠ndices apropiados

---

## üîÑ PARTE 6: UPDATER SERVICE

### 6.1 Model Registry Auto-Update

#### ¬øC√≥mo mantener el cat√°logo actualizado?

**Problema:** Los precios de modelos LLM cambian frecuentemente. El sistema debe actualizarse sin intervenci√≥n manual.

**Soluci√≥n: Servicio background que sincroniza desde fuente central**

**Flujo completo:**

1. **Source of Truth**
   - GitHub repo p√∫blico con registry.json
   - Actualizado por scraper/bot que monitorea p√°ginas de pricing
   - Versi√≥n centralizada que todos los gateways consultan

2. **Scheduler en Updater Service**
   ```python
   schedule.every().day.at("00:00").do(update_registry)
   ```
   - Ejecutar una vez al d√≠a
   - Horario de baja actividad (medianoche UTC)

3. **Proceso de actualizaci√≥n:**

   a. **Fetch from GitHub**
   ```
   URL: https://raw.githubusercontent.com/user/repo/main/registry.json
   Method: HTTP GET
   Timeout: 10s
   ```

   b. **Validate Structure**
   ```python
   def validate_registry(data):
     required_fields = ["version", "updated_at", "models"]
     for model in data["models"]:
       assert "id" in model
       assert "pricing" in model
       assert "specs" in model
   ```

   c. **Compare Versions**
   ```python
   current_version = load_local_registry()["version"]
   new_version = fetched_data["version"]
   
   if new_version <= current_version:
     return  # No update needed
   ```

   d. **Backup Current**
   ```bash
   cp data/models.json data/models.json.bak
   ```

   e. **Write New Version**
   ```python
   with open("data/models.json", "w") as f:
     json.dump(fetched_data, f, indent=2)
   ```

   f. **Trigger Backend Reload**
   - Backend detecta cambio en archivo (watchdog o polling)
   - Recarga ModelRegistry sin reiniciar servidor
   - Log de cambios detectados

4. **Detecci√≥n de Cambios Importantes**

   **Price Changes:**
   ```python
   for model in new_models:
     old_price = old_registry[model.id].pricing
     new_price = model.pricing
     if new_price != old_price:
       alert(f"Price changed for {model.id}: {old_price} ‚Üí {new_price}")
   ```

   **New Models:**
   ```python
   new_model_ids = set(m.id for m in new_models)
   old_model_ids = set(m.id for m in old_models)
   added = new_model_ids - old_model_ids
   if added:
     alert(f"New models available: {added}")
   ```

   **Deprecated Models:**
   ```python
   deprecated = old_model_ids - new_model_ids
   if deprecated:
     alert(f"Models removed: {deprecated}")
   ```

5. **Notificaciones**
   - Log en archivo: `/var/log/updater.log`
   - Email a admin (opcional)
   - Webhook a Slack/Discord (opcional)
   - Mostrar banner en dashboard si hay cambios cr√≠ticos

**Consideraciones:**
- Manejar errores de red: si fetch falla, mantener registry actual
- Validar integridad: checksum o firma digital del registry
- Permitar rollback manual: `docker exec updater python rollback.py`
- Implementar feature flags: permitir desactivar modelos sin eliminarlos
- Versionado sem√°ntico: major.minor.patch para registry

---

## üé® PARTE 7: FRONTEND DASHBOARD

### 7.1 Arquitectura de Frontend

#### Stack Next.js + React Query

**Decisiones de dise√±o:**

1. **Next.js App Router (no Pages Router)**
   - Usar Server Components donde sea posible
   - Client Components solo cuando se necesita interactividad
   - Layouts compartidos para evitar re-renders

2. **React Query para Data Fetching**
   ```javascript
   const { data, isLoading, error } = useQuery({
     queryKey: ['analytics', 'overview'],
     queryFn: () => api.getAnalyticsOverview(),
     refetchInterval: 30000  // Re-fetch cada 30s
   })
   ```
   - Cach√© autom√°tico de queries
   - Optimistic updates para mutaciones
   - Retry autom√°tico en errores

3. **Shadcn/ui para Componentes**
   - Componentes pre-hechos y customizables
   - Integrados con Tailwind CSS
   - Accesibles (a11y) por defecto

**Estructura de rutas:**
```
app/
‚îú‚îÄ‚îÄ page.tsx                    # Landing page
‚îú‚îÄ‚îÄ auth/
‚îÇ   ‚îú‚îÄ‚îÄ login/page.tsx
‚îÇ   ‚îî‚îÄ‚îÄ signup/page.tsx
‚îú‚îÄ‚îÄ dashboard/
‚îÇ   ‚îú‚îÄ‚îÄ layout.tsx              # Layout con sidebar
‚îÇ   ‚îú‚îÄ‚îÄ page.tsx                # Overview dashboard
‚îÇ   ‚îú‚îÄ‚îÄ keys/page.tsx           # Gateway keys
‚îÇ   ‚îú‚îÄ‚îÄ models/page.tsx         # Model catalog
‚îÇ   ‚îî‚îÄ‚îÄ analytics/page.tsx      # Analytics detallados
```

---

### 7.2 Sistema de Autenticaci√≥n Frontend

#### ¬øC√≥mo manejar auth en el cliente?

**Flujo de login:**

1. **Usuario submite formulario**
   ```javascript
   const handleLogin = async (email, password) => {
     const response = await fetch('/api/auth/login', {
       method: 'POST',
       body: JSON.stringify({ email, password })
     })
     const { token, user } = await response.json()
     
     // Guardar token en localStorage
     localStorage.setItem('token', token)
     
     // Redirigir a dashboard
     router.push('/dashboard')
   }
   ```

2. **Interceptor para agregar token**
   ```javascript
   // lib/api.ts
   const api = axios.create({
     baseURL: 'http://localhost:8000'
   })
   
   api.interceptors.request.use(config => {
     const token = localStorage.getItem('token')
     if (token) {
       config.headers.Authorization = `Bearer ${token}`
     }
     return config
   })
   ```

3. **Middleware de protecci√≥n de rutas**
   ```javascript
   // middleware.ts
   export function middleware(request) {
     const token = request.cookies.get('token')
     
     if (!token && request.nextUrl.pathname.startsWith('/dashboard')) {
       return NextResponse.redirect(new URL('/auth/login', request.url))
     }
   }
   ```

4. **Hook de autenticaci√≥n**
   ```javascript
   function useAuth() {
     const [user, setUser] = useState(null)
     
     useEffect(() => {
       const token = localStorage.getItem('token')
       if (token) {
         // Verificar token con backend
         api.get('/api/auth/me').then(response => {
           setUser(response.data)
         })
       }
     }, [])
     
     const logout = () => {
       localStorage.removeItem('token')
       setUser(null)
       router.push('/auth/login')
     }
     
     return { user, logout }
   }
   ```

**Consideraciones:**
- Renovar token autom√°ticamente antes de expiraci√≥n (refresh tokens)
- Limpiar localStorage en logout
- Manejar expiraci√≥n de token: si backend retorna 401, redirigir a login
- No almacenar informaci√≥n sensible en localStorage (solo token)

---

### 7.3 Dashboard de Analytics

#### ¬øC√≥mo visualizar m√©tricas?

**Componentes principales:**

1. **MetricsCard** (4 cards en la parte superior)
   ```jsx
   <div className="grid grid-cols-4 gap-4">
     <MetricsCard 
       title="Total Cost"
       value="$4.52"
       change="+12%"
       trend="up"
     />
     <MetricsCard 
       title="Requests"
       value="1,523"
       change="+8%"
       trend="up"
     />
     <MetricsCard 
       title="Avg Latency"
       value="2.1s"
       change="-5%"
       trend="down"
     />
     <MetricsCard 
       title="Cache Rate"
       value="23.5%"
       change="+3%"
       trend="up"
     />
   </div>
   ```

2. **CostChart** (gr√°fico de l√≠nea de √∫ltimos 7 d√≠as)
   ```jsx
   <LineChart data={costData}>
     <XAxis dataKey="date" />
     <YAxis />
     <Line dataKey="cost" stroke="#3b82f6" />
     <Tooltip />
   </LineChart>
   ```

3. **ModelDistributionChart** (pie chart de modelos usados)
   ```jsx
   <PieChart>
     <Pie 
       data={modelData}
       dataKey="requests"
       nameKey="model"
     />
     <Tooltip />
     <Legend />
   </PieChart>
   ```

4. **RecentRequestsTable** (tabla de √∫ltimos 10 requests)
   ```jsx
   <Table>
     <TableHeader>
       <TableRow>
         <TableHead>Timestamp</TableHead>
         <TableHead>Model</TableHead>
         <TableHead>Tokens</TableHead>
         <TableHead>Cost</TableHead>
         <TableHead>Latency</TableHead>
       </TableRow>
     </TableHeader>
     <TableBody>
       {requests.map(req => (
         <TableRow key={req.id}>
           <TableCell>{formatTime(req.created_at)}</TableCell>
           <TableCell>{req.model}</TableCell>
           <TableCell>{req.total_tokens}</TableCell>
           <TableCell>${req.cost_usd}</TableCell>
           <TableCell>{req.latency_ms}ms</TableCell>
         </TableRow>
       ))}
     </TableBody>
   </Table>
   ```

**Consideraciones:**
- Implementar loading skeletons mientras cargan datos
- Manejar estados de error con mensajes claros
- Actualizar datos en tiempo real (polling cada 30s o WebSocket)
- Responsive design: en mobile, cards se apilan verticalmente

---

## üß™ PARTE 8: TESTING Y CALIDAD

### 8.1 Estrategia de Testing

#### ¬øQu√© testear y c√≥mo?

**Niveles de testing:**

1. **Unit Tests** (componentes individuales)
   - Request Classifier: verificar que clasifica correctamente
   - Routing Engine: verificar scoring y selecci√≥n
   - KeyVault: verificar encriptaci√≥n/desencriptaci√≥n
   - Cache Manager: verificar LRU eviction y TTL

2. **Integration Tests** (flujos completos)
   - Login ‚Üí Dashboard ‚Üí Ver m√©tricas
   - Agregar provider key ‚Üí Hacer request ‚Üí Ver en logs
   - Request con cache miss ‚Üí cache hit en segundo request

3. **End-to-End Tests** (desde UI)
   - Usuario se registra ‚Üí agrega OpenAI key ‚Üí hace test request ‚Üí ve costo

**Herramientas:**

- **Backend**: pytest
  ```python
  def test_classifier_simple_request():
    messages = [{"role": "user", "content": "Hello"}]
    result = classifier.classify(messages)
    assert result["complexity"] == "simple"
    assert result["estimated_tokens"] < 500
  ```

- **Frontend**: Vitest + React Testing Library
  ```javascript
  test('MetricsCard displays correct value', () => {
    render(<MetricsCard title="Cost" value="$4.52" />)
    expect(screen.getByText('$4.52')).toBeInTheDocument()
  })
  ```

- **E2E**: Playwright
  ```javascript
  test('complete user flow', async ({ page }) => {
    await page.goto('http://localhost:3000/auth/login')
    await page.fill('input[name="email"]', 'test@example.com')
    await page.fill('input[name="password"]', 'password123')
    await page.click('button[type="submit"]')
    await expect(page).toHaveURL('/dashboard')
  })
  ```

**Consideraciones:**
- Target: 80%+ code coverage en backend core services
- Mockear llamadas externas (providers) en tests
- Usar fixtures para datos de prueba consistentes
- CI/CD: ejecutar tests en cada push a main

---

## üöÄ PARTE 9: DEPLOYMENT Y PRODUCCI√ìN

### 9.1 Preparaci√≥n para Producci√≥n

#### ¬øQu√© cambios hacer para prod?

**Diferencias Dev vs Prod:**

| Aspecto | Development | Production |
|---------|-------------|------------|
| **Debug** | ON | OFF |
| **Frontend Port** | 3000 (expuesto) | Interno o detr√°s de proxy |
| **Backend Port** | 8000 (expuesto) | Expuesto con HTTPS |
| **Database** | SQLite en volume local | SQLite con backups autom√°ticos |
| **Logs** | Console output | Archivo + sistema de logs (ELK/Loki) |
| **Secrets** | .env local | Variables de entorno inyectadas |
| **Updates** | Manual | Autom√°ticos con GitHub Actions |

**Checklist de producci√≥n:**

1. **Seguridad**
   - [ ] Cambiar SECRET_KEY y MASTER_ENCRYPTION_KEY
   - [ ] Habilitar HTTPS con certificado SSL (Let's Encrypt)
   - [ ] Configurar CORS restringido (no `*`)
   - [ ] Implementar rate limiting estricto
   - [ ] Habilitar helmet/security headers

2. **Performance**
   - [ ] Habilitar compresi√≥n gzip
   - [ ] Configurar CDN para frontend est√°tico
   - [ ] Optimizar im√°genes y assets
   - [ ] Implementar caching de responses

3. **Monitoring**
   - [ ] Configurar health checks (Docker)
   - [ ] Implementar logging estructurado
   - [ ] Configurar alertas (email/Slack) para errores
   - [ ] Exponer m√©tricas de Prometheus

4. **Backups**
   - [ ] Backup diario de gateway.db
   - [ ] Versionado de models.json
   - [ ] Snapshot de vol√∫menes Docker

5. **CI/CD**
   - [ ] GitHub Actions para tests autom√°ticos
   - [ ] Build autom√°tico de Docker images
   - [ ] Deploy autom√°tico en merge a main

**docker-compose.prod.yml:**
```yaml
services:
  frontend:
    image: ghcr.io/user/gateway-frontend:latest
    restart: always
    environment:
      - NODE_ENV=production
    # Puerto interno, no expuesto p√∫blicamente
    
  backend:
    image: ghcr.io/user/gateway-backend:latest
    restart: always
    ports:
      - "443:8000"  # HTTPS
    environment:
      - DEBUG=false
      - SECRET_KEY=${SECRET_KEY}
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
```

---

## üìù PARTE 10: DOCUMENTACI√ìN Y MANTENIMIENTO

### 10.1 Documentaci√≥n para Usuarios

#### ¬øQu√© documentar para los usuarios del gateway?

**1. README.md completo**
   - Descripci√≥n del proyecto
   - Features principales
   - Quick start guide
   - Requisitos del sistema
   - Instrucciones de instalaci√≥n

**2. API Documentation (OpenAPI/Swagger)**
   ```yaml
   openapi: 3.0.0
   paths:
     /v1/chat/completions:
       post:
         summary: Main gateway endpoint
         requestBody:
           content:
             application/json:
               schema:
                 type: object
                 properties:
                   messages:
                     type: array
                   temperature:
                     type: number
         responses:
           200:
             description: Success
   ```

**3. User Guide**
   - C√≥mo registrarse
   - C√≥mo agregar API keys de proveedores
   - C√≥mo usar el gateway en tu app
   - Ejemplos de c√≥digo (cURL, Python, JavaScript)
   - Interpretaci√≥n de m√©tricas

**4. FAQ**
   - ¬øC√≥mo se calcula el costo?
   - ¬øQu√© modelos est√°n disponibles?
   - ¬øC√≥mo funciona el cache?
   - ¬øQu√© pasa si mi API key expira?

**Consideraciones:**
- Mantener docs sincronizadas con c√≥digo
- Incluir ejemplos pr√°cticos en todos los endpoints
- Versionar docs junto con el software

---

## ‚úÖ Checklist Final de Implementaci√≥n

### Antes de considerar el proyecto "completo":

**Backend:**
- [ ] Todos los endpoints implementados y documentados
- [ ] Tests unitarios >80% coverage
- [ ] Manejo de errores robusto
- [ ] Logging completo
- [ ] Rate limiting funcional
- [ ] Encriptaci√≥n de keys verificada

**Frontend:**
- [ ] Todas las p√°ginas responsive
- [ ] Loading states y error handling
- [ ] Formularios validados
- [ ] Charts funcionando correctamente
- [ ] Tema consistente (light/dark mode opcional)

**Infrastructure:**
- [ ] Docker Compose funcional
- [ ] Vol√∫menes persistentes configurados
- [ ] Secrets manejados correctamente
- [ ] Health checks implementados

**Documentation:**
- [ ] README completo
- [ ] API docs generadas
- [ ] Gu√≠a de instalaci√≥n
- [ ] Ejemplos de uso
- [ ] Troubleshooting guide

**Security:**
- [ ] Passwords hasheados
- [ ] API keys encriptadas
- [ ] JWT tokens seguros
- [ ] CORS configurado
- [ ] Input validation en todos los endpoints

**Testing:**
- [ ] Tests unitarios pasando
- [ ] Tests de integraci√≥n pasando
- [ ] E2E tests cr√≠ticos cubiertos
- [ ] Load testing b√°sico realizado

---

## üéì Conceptos Clave a Dominar

### Para implementar exitosamente este proyecto, debes entender:

1. **Backend Development**
   - REST API design
   - Database modeling (SQL)
   - Authentication & authorization (JWT)
   - Cryptography basics (Fernet, bcrypt)
   - Async programming (si usas async/await)

2. **Frontend Development**
   - React hooks y componentes
   - State management (Context/Zustand)
   - Data fetching (React Query)
   - Responsive design (Tailwind CSS)
   - Forms y validaci√≥n

3. **DevOps**
   - Docker containers
   - Docker Compose orchestration
   - Volumes y networks
   - Environment variables
   - Basic security practices

4. **System Design**
   - Microservices architecture
   - Caching strategies
   - Load balancing concepts
   - Error handling & retry logic
   - Monitoring & logging

---

*Documento creado: 2026-01-11*
*Versi√≥n: 1.0*
